{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"송민철_Ex_Estimation_and_filtering.ipynb","provenance":[{"file_id":"https://gist.github.com/jonghank/46597214ce4d62067e752402114527c3#file-ex_estimation_and_filtering-ipynb","timestamp":1589953126772}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"GY_tlKGhFh6V","colab_type":"text"},"source":["# Estimation and filtering\n","\n","$$\n","\\newcommand{\\eg}{{\\it e.g.}}\n","\\newcommand{\\ie}{{\\it i.e.}}\n","\\newcommand{\\argmin}{\\operatornamewithlimits{argmin}}\n","\\newcommand{\\mc}{\\mathcal}\n","\\newcommand{\\mb}{\\mathbb}\n","\\newcommand{\\mf}{\\mathbf}\n","\\newcommand{\\minimize}{{\\text{minimize}}}\n","\\newcommand{\\diag}{{\\text{diag}}}\n","\\newcommand{\\cond}{{\\text{cond}}}\n","\\newcommand{\\rank}{{\\text{rank }}}\n","\\newcommand{\\range}{{\\mathcal{R}}}\n","\\newcommand{\\null}{{\\mathcal{N}}}\n","\\newcommand{\\tr}{{\\text{trace}}}\n","\\newcommand{\\dom}{{\\text{dom}}}\n","\\newcommand{\\dist}{{\\text{dist}}}\n","\\newcommand{\\R}{\\mathbf{R}}\n","\\newcommand{\\SM}{\\mathbf{S}}\n","\\newcommand{\\ball}{\\mathcal{B}}\n","\\newcommand{\\bmat}[1]{\\begin{bmatrix}#1\\end{bmatrix}}\n","$$"]},{"cell_type":"markdown","metadata":{"id":"dcn4VDPcFh6Y","colab_type":"text"},"source":["__<div style=\"text-align: right\"> EE370: Software lab, Kyung Hee University. </div>__\n","_<div style=\"text-align: right\"> Jong-Han Kim (jonghank@khu.ac.kr) </div>_\n"]},{"cell_type":"markdown","metadata":{"id":"R0aSihjddZbr","colab_type":"text"},"source":["A discrete-time linear dynamical system consists of a sequence of state vectors $x_t \\in \\R^n$, indexed by time $t\\in \\{0,\\dots,N-1\\}$ and dynamics equations\n","\n","<br>\n","\n","$$\n","\\begin{aligned}\n","  x_{t+1} &= Ax_t + Bw_t \\\\\n","  y_{t} &= Cx_t + n_t   \n","\\end{aligned}\n","$$\n","\n","<br>\n","\n","where $w_t\\in\\R^m$ is an disturbance input to the dynamical system (say, a wind force acting on a drone), $y_t\\in\\R^r$ is a  measurement vector, $n_t\\in\\R^r$ is the measurement noise, $A$ is the drift matrix, $B$ is the input matrix, and $C$ is the observation matrix. Note that the state variable $x_t$ for $t=0,\\dots,N$ is not available to us. \n","\n","The goal of this problem is to estimate $x_t$ for $t=0,\\dots,N−1$, given $A$, $B$, $C$, and $y_t$ for $t=0,\\dots,N$.\n","\n","<br>"]},{"cell_type":"markdown","metadata":{"id":"Ib0jM2wPwZIS","colab_type":"text"},"source":["Throughout this problem, we will consider a one dimensional vehicle tracking problem with state $x_t=(p_t, v_t)\\in\\R^2$, where the states are the position, $p_t$, and the velocity, $v_t$, of the vehicle. The vehicle is influenced by an unknown disturbance force $w_t$, and we observe noisy measurements of the vehicle's position, $y_t\\in\\R$.\n","\n","This is governed by \n","\n","<br>\n","\n","$$\n","\\begin{aligned}\n","  \\dot{v} &= w - \\gamma v  \\\\\n","  \\dot{p} &= v  \n","\\end{aligned}\n","$$\n","\n","<br>\n","\n","where a small constant $\\gamma$ is the friction (or damping) coefficient. Trapezoidal integration assuming constant acceleration during the sampling interval gives,\n","\n","<br>\n","\n","$$\n","\\begin{aligned}\n","  v_{t+1} &= v_t + {\\Delta t}\\left( w_t - \\gamma v_t  \\right) \\\\\n","  &= \\left(1-\\gamma \\Delta t\\right) v_t + \\Delta t w_t \\\\\n","  p_{t+1} &= p_t + \\frac{\\Delta t}{2}\\left( v_t + v_{t+1} \\right)  \\\\ \n","  &= p_t + \\frac{\\Delta t}{2}\\left( v_t + \\left(1-\\gamma \\Delta t\\right) v_t + \\Delta t w_t \\right)  \\\\ \n","  &= p_t +  \\left(\\Delta t-\\frac{1}{2}\\gamma\\Delta t^2\\right) v_t + \\frac{1}{2} \\Delta t^2 w_t\n","\\end{aligned}\n","$$\n","\n","<br>\n","\n","Now we have the aboveThen the following matrices describe the above dynamics.\n","\n","<br>\n","\n","$$\n","\\begin{aligned}\n","  x_{t+1} &= Ax_t + Bw_t \\\\\n","  y_{t} &= Cx_t + n_t   \n","\\end{aligned}\n","$$\n","\n","<br>\n","\n","with $x_t = (p_t, v_t)$ and\n","\n","<br>\n","\n","$$\n","A = \\bmat{\n","1 & \\left(1-0.5\\gamma\\Delta t\\right)\\Delta t \\\\\n","0 & 1-\\gamma\\Delta t \n","}, \\quad \n","B = \\bmat{\n","0.5\\Delta t^2 \\\\\n","\\Delta t\n","}, \\quad\n","C = \\bmat{1 & 0 }\n","$$\n","\n","<br>\n","\n","We further assume that the two noise components, $w_t$ and $n_t$, both are independent and identically distributed (IID) standard normal random variables. In other words, $w_t \\sim \\mathcal{N}(0,1)$ and $n_t \\sim \\mathcal{N}(0,1)$.\n","\n","<br>\n","\n","The following simulates the above for $0\\le t \\le 50$ with $\\Delta t=0.05$ and $\\gamma=0.05$.\n"]},{"cell_type":"code","metadata":{"id":"KtJUjBP1hicG","colab_type":"code","colab":{}},"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","\n","N = 1000 # number of timesteps\n","T = 50 # time will vary from 0 to T with step delt\n","ts = np.linspace(0,T,N+1)\n","delt = T/N\n","gamma = .05 # damping, 0 is no damping\n","\n","A = np.zeros((2,2))\n","B = np.zeros((2,1))\n","C = np.zeros((1,2))\n","\n","A[0,0] = 1\n","A[0,1] = (1-gamma*delt/2)*delt\n","A[1,1] = 1 - gamma*delt\n","\n","B[0,0] = delt**2/2\n","B[1,0] = delt\n","\n","C[0,0] = 1\n","\n","np.random.seed(370)\n","\n","x = np.zeros((2,N+1))\n","x[:,0] = [0,0]\n","y = np.zeros((1,N))\n","\n","w = np.random.randn(1,N)\n","n = np.random.randn(1,N)\n","\n","for t in range(N):\n","    y[:,t] = C.dot(x[:,t]) + n[:,t]\n","    x[:,t+1] = A.dot(x[:,t]) + B.dot(w[:,t])\n","    \n","x_true = x.copy()\n","w_true = w.copy()\n","n_true = n.copy()\n","\n","plt.figure(figsize=(8,6), dpi=100)\n","plt.subplot(2,1,1)\n","plt.plot(ts,x[0,:], label='position (true)')\n","plt.plot(ts[:-1],y[0,:], alpha=0.5, label='position (measured)')\n","plt.ylabel(r'$p$')\n","plt.legend()\n","plt.grid()\n","plt.subplot(2,1,2)\n","plt.plot(ts,x[1,:], label='velocity (true)')\n","plt.xlabel('time')\n","plt.ylabel(r'$v$')\n","plt.legend()\n","plt.grid()\n","plt.show()\n","\n","plt.figure(figsize=(8,6), dpi=100)\n","plt.subplot(2,1,1)\n","plt.plot(ts[:-1],w_true[0,:], label='wind force (true)')\n","plt.ylabel(r\"$w$\")\n","plt.legend()\n","plt.grid()\n","plt.subplot(2,1,2)\n","plt.plot(ts[:-1],n_true[0,:], label='sensor noise (true)')\n","plt.xlabel('time')\n","plt.ylabel(r'$n$')\n","plt.legend()\n","plt.grid()\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7vJl7RshOiyd","colab_type":"text"},"source":["So the problem is now to estimate $x_t = (p_t, v_t)$ with the given position measurement, $y_t$. We use the hat notation to denote the estimates. For example,\n","\n","<br>\n","\n","$$\n","  \\hat{x}_t = (\\hat{p}_t, \\hat{v}_t)\n","$$\n","\n","<br>\n","\n","is the position and velocity estimates.\n","\n","<br>"]},{"cell_type":"markdown","metadata":{"id":"Ewzy1QQp2-Uf","colab_type":"text"},"source":["<br>\n","\n","**(Problem 1)**\n","A very naive approach to compute the above state estimates is as follows. \n","\n","1) Since the position ($p_t$) was measured by $y_t$, we believe our measurement entirely. In other words, we let \n","\n","<br>\n","\n","$$\n","\\hat{p}^{\\text{naive}}_t = y_t\n","$$\n","\n","<br>\n","\n","2) Since we don't have direct measurements on the velocity ($v_t$), we numerically differentiate $\\hat{p}^{\\text{naive}}_t$ to compute $\\hat{v}^{\\text{naive}}_t$. In other words, we let\n","\n","<br>\n","\n","$$\n","  \\hat{v}^{\\text{naive}}_t = \\frac{\\hat{p}^{\\text{naive}}_t - \\hat{p}^{\\text{naive}}_{t-1}}{\\Delta t} = \\frac{y_t-y_{t-1}}{\\Delta t}\n","$$\n","\n","<br>\n","\n","Implement this, and compare the state estimates with the true state variables. Overlap $\\hat{p}^{\\text{naive}}_t$ and ${p}_t$ on a single plot, and $\\hat{v}^{\\text{naive}}_t$ and ${v}_t$ on another plot."]},{"cell_type":"code","metadata":{"id":"pVWbQG3h29jl","colab_type":"code","colab":{}},"source":["# your code here\n","\n","# your code here\n","v_hat_native = np.zeros(N)\n","for i in range(len(y[0])):\n","  if i == 0:\n","    v_hat_native[i] = 0\n","  else:\n","    v_hat_native[i] = (y[0][i] - y[0][i-1]) / delt\n","\n","plt.figure(figsize=(8,6), dpi=100)\n","plt.subplot(211)\n","plt.title('Native Estimation')\n","plt.plot(ts, x[0,:], label='$p_t$')\n","plt.plot(ts[:-1], y[0,:], alpha=0.5, label='$p^{native}_t$')\n","plt.legend()\n","\n","plt.subplot(212)\n","plt.plot(ts, x[1,:], label='$v_t$')\n","plt.plot(ts[:-1], v_hat_native, alpha=0.5, label='$v^{native}_t$')\n","plt.legend()\n","\n","\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"a-9z_LQdqjlI","colab_type":"text"},"source":["<br>\n","\n","**(Problem 2)** Since the above estimates look severely corrupted by shigh frequency noise components, we would like to use low pass filters to smooth them out. Though there are sophisticated ways of designing and implementing the discrete-time low pass filters, we would go with a simle first-order recursive form described below. The low-pas-filtered signal $\\hat{p}^{\\text{lpf}}_t$ for the naive estimate $\\hat{p}^{\\text{naive}}_t$ is given by \n","\n","<br>\n","\n","$$\n","\\hat{p}^{\\text{lpf}}_{t+1} = a  \\hat{p}^{\\text{lpf}}_{t} + b \\left(\\hat{p}^{\\text{naive}}_{t+1} + \\hat{p}^{\\text{naive}}_{t}\\right) \n","$$\n","\n","<br>\n","\n","where we will use $(a,b)=(0.9047619,0.04761905)$ for position estimates and $(a,b)=(0.99004975,0.00497512)$ for velocity estimates. The following cell computes these numbers, but you don't have to care about it."]},{"cell_type":"code","metadata":{"id":"CroMwEqSwMia","colab_type":"code","colab":{}},"source":["import scipy.signal as sps\n","bw_p = 2\n","bw_v = 0.2\n","lpf_p = sps.cont2discrete(([bw_p],[1.,bw_p]), delt, method='bilinear')\n","lpf_v = sps.cont2discrete(([bw_v],[1.,bw_v]), delt, method='bilinear')\n","print(lpf_p)\n","print(lpf_v)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WtpebedKD32c","colab_type":"text"},"source":["Using these coefficients, implement the low pass filter and compare the state estimates with the true state variables. Overlap $\\hat{p}^{\\text{lpf}}_t$ and ${p}_t$ on a single plot, and $\\hat{v}^{\\text{lpf}}_t$ and ${v}_t$ on another plot."]},{"cell_type":"code","metadata":{"id":"_iDyMjo98IT0","colab_type":"code","colab":{}},"source":["# your code here\n","\n","p_hat_lpf = np.zeros(len(y[0,:]))\n","v_hat_lpf = np.zeros(len(v_hat_native))\n","\n","for i in range(len(y[0,:])-1):\n","  p_hat_lpf[i+1] = -lpf_p[1][1]*p_hat_lpf[i] + lpf_p[0][0][0]*(y[0][i+1] + y[0][i])\n","\n","for i in range(len(v_hat_native)-1):\n","  v_hat_lpf[i+1] = -lpf_v[1][1]*v_hat_lpf[i] + lpf_v[0][0][0]*(v_hat_native[i+1] + v_hat_native[i])\n","\n","plt.figure(figsize=(8,6), dpi=100)\n","plt.subplot(211)\n","plt.title('LPF Estimation')\n","plt.plot(ts, x[0,:], label='position (true)')\n","plt.plot(ts[:-1], p_hat_lpf, alpha=0.5, label='position (LPF)')\n","plt.legend()\n","\n","plt.subplot(212)\n","plt.plot(ts, x[1,:], label='velocity (true)')\n","plt.plot(ts[:-1], v_hat_lpf, alpha=0.5, label='velocity (LPF)')\n","plt.legend()\n","\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KZi91LMDvcV_","colab_type":"text"},"source":["<br>\n","\n","**(Problem 3)** An alpha beta filter presumes that a system is adequately approximated by a model having two internal states, where the first state is obtained by integrating the value of the second state over time. Measured system output values correspond to observations of the first model state, plus disturbances. This very low order approximation is adequate for many simple systems, for example, mechanical systems where position is obtained as the time integral of velocity. \n","\n","Assuming that velocity remains approximately constant over the small time interval $\\Delta t$ between measurements, the position state is projected forward to predict its value at the next sampling time using \n","\n","<br>\n","\n","$$\n","\\tilde{p}_t = \\hat{p}_{t-1} + \\Delta t \\hat{v}_{t-1}\n","$$\n","\n","<br>\n","\n","Since velocity variable $v$ is presumed constant, its projected value at the next sampling time equals the current value.\n","\n","<br>\n","\n","$$\n","\\tilde{v}_t = \\hat{v}_{t-1}\n","$$\n","\n","<br>\n","\n","If additional information is known about how a driving function will change the $v$ state during each time interval, this can be modified to include it.\n","\n","The output measurement is expected to deviate from the prediction because of noise and dynamic effects not included in the simplified dynamic model. This prediction error $r_t$ is also called the residual or innovation, \n","\n","<br>\n","\n","$$\n"," r_t = y_t - \\tilde{p}_t \n","$$\n","\n","<br>\n","\n","Suppose that residual $r_t$ is positive. This could result because the previous $p_t$ estimate was low, the previous v was low, or some combination of the two. The alpha beta filter takes selected alpha and beta constants (from which the filter gets its name), uses alpha times the deviation $r_t$ to correct the position estimate, and uses beta times the deviation $r_t$ to correct the velocity estimate. An extra $\\Delta t$ factor conventionally serves to normalize magnitudes of the multipliers.\n","\n","<br>\n","\n","$$\n","\\begin{aligned}\n","\\hat{p}_{t+1} &= \\tilde{p}_{t} + \\alpha\\left(y_t - \\tilde{p}_t \\right) \\\\\n","\\hat{v}_{t+1} &= \\tilde{v}_{t} + \\frac{\\beta}{\\Delta t} \\left(y_t - \\tilde{p}_t \\right) \n","\\end{aligned}\n","$$\n","\n","<br>\n","\n","The corrections can be considered small steps along an estimate of the gradient direction. As these adjustments accumulate, error in the state estimates is reduced. Typical choices are \n","\n","<br>\n","\n","$$ \n","0 < \\alpha , \\beta < 1 \n","$$\n","\n","<br>\n","\n","Values of alpha and beta typically are adjusted experimentally. In general, larger alpha and beta gains tend to produce faster response for tracking transient changes, while smaller alpha and beta gains reduce the level of noise in the state estimates. If a good balance between accurate tracking and noise reduction is found, and the algorithm is effective, filtered estimates are more accurate than the direct measurements. This motivates calling the alpha-beta process a filter.\n","\n","Implement this alpha beta filter. Experiment with various $\\alpha$ and $\\beta$ on your given data set to select the best $\\alpha$ and $\\beta$ that works on your signals."]},{"cell_type":"code","metadata":{"id":"9w3-Q-yi3lrk","colab_type":"code","colab":{}},"source":["# your code here\n","\n","alpha = 0.1\n","beta = 0.004\n","\n","p_tilde = np.zeros(len(y[0,:]))\n","v_tilde = np.zeros(len(y[0,:]))\n","p_hat_ab = np.zeros(len(y[0,:]))\n","v_hat_ab = np.zeros(len(y[0,:]))\n","r = np.zeros(len(y[0,:]))\n","p_tilde[0] = y[0,0]\n","p_hat_ab[0] = y[0,0]\n","v_tilde[0] = 0\n","v_hat_ab[0] = 0\n","\n","for i in range(0, len(p_hat_ab)-1):\n","  r[i] = y[0][i] - p_tilde[i]\n","  p_hat_ab[i+1] = p_tilde[i] + (alpha * r[i])\n","  v_hat_ab[i+1] = v_tilde[i] + (beta/delt) * r[i]\n","  p_tilde[i+1] = p_hat_ab[i] + delt*v_hat_ab[i]\n","  v_tilde[i+1] = v_hat_ab[i]\n","\n","\n","\n","plt.figure(figsize=(8,6), dpi=100)\n","plt.subplot(211)\n","plt.title('alpha-beta Estimation')\n","plt.plot(ts, x[0,:], label='position (true)')\n","plt.plot(ts[:-1], p_hat_ab, alpha=0.5, label='position ($a-b$ filtered)')\n","plt.legend()\n","\n","plt.subplot(212)\n","plt.plot(ts, x[1,:], label='velocity (true)')\n","plt.plot(ts[:-1], v_hat_ab, alpha=0.5, label='velocity ($a-b$ filtered)')\n","plt.legend()\n","\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8w-FLuZAAmTF","colab_type":"text"},"source":["<br> \n","\n","**(Problem 4)** A better (actually the best) way in short is as follows. We begin with the state estimate, $\\hat{x}_t$, and the error covariance of the state variable, $\\Sigma_t$, and will recursively propagate them.\n","\n","<br>\n","\n","\\begin{align*}\n","  \\hat{x}_t &= \\mathbf{E}\\left(x_t \\mid y_0, y_1, \\dots, y_{t-1} \\right) \\\\\n","  \\Sigma_t &= \\mathbf{cov}\\left(x_t \\mid y_0, y_1, \\dots, y_{t-1} \\right)\n","\\end{align*}\n","\n","<br>\n","\n","Here, $\\hat{x}_t$ can be interpreted as the state estimate at time $t$ given observations up to time $t-1$, and ${\\Sigma}_t$ is the error covariance matrix which explains the estimated accuracy of the state estimates given observations up to time $t-1$. These should be described in way more details, however we will not go into that and the above simple explanation would be sufficient for understanding elementary mechanisms of optimal state estimation. \n","\n","<br>\n","\n","1) The state propagation step is given by:\n","\n","<br>\n","\n","$$\n","\\tilde{x}_{t+1} = A \\hat{x}_t\n","$$\n","\n","<br>\n","\n","2) Compute the output prediction:\n","\n","<br>\n","\n","$$\n","  \\hat{y}_t = C\\hat{x}_t\n","$$\n","\n","<br>\n","\n","Then the quantity $r_t = y_t-\\hat{y}_t$ presents the prediction error on your output, and can be an indirect measure of your model accuracy.\n","\n","<br>\n","\n","3) Compute the state estimate:\n","\n","<br>\n","\n","$$\n","  \\hat{x}_{t+1} = \\tilde{x}_t + K_t \\left(y_t-\\hat{y}_t \\right)\n","$$\n","\n","<br>\n","\n","The above can be interpreted as predicting the next state based on your model ($A\\hat{x}_t$) and then compensating it based on the your model accuracy, $K_t \\left(y_t-\\hat{y}_t \\right)$.\n","\n","<br>\n","\n","4) The Kalman gain is described by:\n","\n","<br>\n","\n","$$\n","  K_t = A\\Sigma_tC^T \\left( C\\Sigma_t C^T + \\Sigma_v \\right)^{-1}\n","$$\n","\n","<br>\n","\n","where $\\Sigma_v$ represents the covariance of the measurement noise, $n_t$. Since we assumed the IID zero mean Gaussian random noise with variance 1, we have that $\\Sigma_v=I$.\n","\n","<br>\n","\n","5) The state covariance is updated by:\n","\n","<br>\n","\n","$$\n","  \\Sigma_{t+1} = A\\Sigma_tA^T - A\\Sigma_t C^T \\left(C\\Sigma_t C^T + \\Sigma_v \\right)^{-1}C\\Sigma_t A^T + \\Sigma_w\n","$$\n","\n","<br>\n","\n","where $\\Sigma_w$ represents the covariance of the dicturbance input, $Bw_t$. Since we assumed that $w_t$ follows the IID zero mean Gaussian random noise with variance 1, we have that $\\Sigma_w=BB^T$. This procedure corresponds to conditioning the Gaussian distibution using the new measurement information via Bayesian inference, and propagating it under the affine dynamical relation.\n","\n","<br>\n","\n","Implement this, and compare the state estimates with the true state variables. Compare your results with the naive estimates and the low-pass-filtered estimates. You may simply assume that $\\hat{x}=(0,0)$ and $\\Sigma_0 = 10I$; you will notice that your solution will be robust to changes in these initial conditions.\n","\n","The above procedure is called the _Kalman filtering_, and it turns out to be optimal, in other words most accurate, under some technical conditions."]},{"cell_type":"code","metadata":{"id":"6-v8rkye6bhX","colab_type":"code","colab":{}},"source":["# your code here\n","\n","x_tilde = np.array([np.array([0.,0.]) for i in range(len(y[0,:]))])\n","x_hat = np.array([np.array([0.,0.]) for i in range(len(y[0,:]))])\n","y_hat = np.array([np.array([0.]) for i in range(len(y[0,:]))])\n","sigma = np.array([np.array([[0.,0.], [0.,0.]]) for i in range(len(y[0,:]))])\n","K = np.array([np.array([[0.], [0.]]) for i in range(len(y[0,:]))])\n","\n","sigma[0] = 10 * np.identity(2)\n","\n","for i in range(len(x_hat) - 1):\n","  x_tilde[i+1] = A @ x_hat[i]\n","  y_hat[i] = C @ x_hat[i]\n","  K[i] = A @ sigma[i] @ C.T @ np.linalg.inv(C @ sigma[i] @ C.T + np.identity(1)) \n","  sigma[i+1] = (A @ sigma[i] @ A.T) - (K[i] @ C @ sigma[i] @ A.T) + (B @ B.T)\n","  x_hat[i+1] = x_tilde[i+1] + np.matmul(K[i], (y[0][i] - y_hat[i]))\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"p9PhxoyXlgxq","colab_type":"code","colab":{}},"source":["plt.figure(figsize=(8,6), dpi=100)\n","plt.subplot(211)\n","plt.title('Karman Filter Estimation')\n","plt.plot(ts, x[0,:], label='position (true)')\n","plt.plot(ts[:-1], x_hat[:,0], alpha=0.5, label='position (Karman filtered)')\n","plt.legend()\n","\n","plt.subplot(212)\n","plt.plot(ts, x[1,:], label='velocity (true)')\n","plt.plot(ts[:-1], x_hat[:,1], alpha=0.5, label='velocity (Karman filtered)')\n","plt.legend()\n","\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wPJhPEYQ9bnn","colab_type":"code","colab":{}},"source":["plt.figure(figsize=(8,6), dpi=100)\n","plt.subplot(211)\n","plt.title('Estimate Comparision')\n","plt.plot(ts[:-1], p_hat_lpf, alpha=0.5, label='position (LPF)')\n","plt.plot(ts[:-1], p_hat_ab, alpha=0.5, label='position ($a-b$ filtered)')\n","plt.plot(ts[:-1], x_hat[:,0], alpha=0.5, label='position (Karman filtered)')\n","plt.legend()\n","\n","plt.subplot(212)\n","\n","plt.plot(ts[:-1], v_hat_lpf, alpha=0.5, label='velocity (LPF)')\n","plt.plot(ts[:-1], v_hat_ab, alpha=0.5, label='velocity ($a-b$ filtered)')\n","plt.plot(ts[:-1], x_hat[:,1], alpha=0.5, label='velocity (Karman filtered)')\n","plt.legend()\n","\n","plt.show()"],"execution_count":null,"outputs":[]}]}